{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "#!pip install datasets\n",
    "#!pip install fasttext-wheel\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install scipy\n",
    "#!pip install tensorflow"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-12T17:57:55.825259Z",
     "start_time": "2024-07-12T17:57:49.645798Z"
    }
   },
   "source": [
    "# Import relevant modules\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import os\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import pearsonr"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load the dataset\n",
    "df = load_dataset(\"wikipedia\", \"20220301.en\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^\\w\\s]+', ' ', text)\n",
    "    text = re.sub(r'[ \\n]+', ' ', text)\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = df['train']\n",
    "\n",
    "# Create the file path to store the preprocessed text\n",
    "preprocessed_text_file = 'pt1.txt'\n",
    "\n",
    "# Set the counter as per the text file\n",
    "counter = 1\n",
    "\n",
    "# Open the file for writing\n",
    "with open(preprocessed_text_file, 'w', encoding='utf-8') as f:\n",
    "    # Iterate over the train dataset\n",
    "    for data_point in train_dataset:\n",
    "        text = data_point['text']\n",
    "        \n",
    "        # Perform any preprocessing steps on the text\n",
    "        preprocessed_text = preprocess(text)\n",
    "        \n",
    "        # Write the preprocessed text to the file\n",
    "        f.write(preprocessed_text + '\\n')\n",
    "        print(\"Progress: \", data_point['title'], counter)\n",
    "        if(counter == 1):\n",
    "            break\n",
    "        counter += 1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "100 dimensions cbow--->"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:55:29.241793Z",
     "start_time": "2024-07-11T15:41:56.417447Z"
    }
   },
   "source": [
    "# Train the model (CBOW 100 dimensions)\n",
    "#model = fasttext.train_unsupervised(\"pt1.txt\", model='cbow', dim = 100)\n",
    "#model = fasttext.train_unsupervised(\"pt10.txt\", model='cbow', dim = 100)\n",
    "#model = fasttext.train_unsupervised(\"pt100.txt\", model='cbow', dim = 100)\n",
    "#model = fasttext.train_unsupervised(\"pt1000.txt\", model='cbow', dim = 100)\n",
    "model = fasttext.train_unsupervised(\"pt10000.txt\", model='cbow', dim = 100)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:55:51.825125Z",
     "start_time": "2024-07-11T15:55:45.292891Z"
    }
   },
   "source": [
    "# Save the model\n",
    "model.save_model(\"cbow_model10000.bin\")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:55:54.720632Z",
     "start_time": "2024-07-11T15:55:53.521393Z"
    }
   },
   "source": [
    "# Load the model\n",
    "model1 = fasttext.load_model(\"cbow_model10000.bin\")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "300 dimensions cbow----->"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:15:52.121168Z",
     "start_time": "2024-07-11T16:26:15.667623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the model (CBOW 300 dimensions)\n",
    "#model = fasttext.train_unsupervised(\"pt1.txt\", model='cbow', dim = 300)\n",
    "#model = fasttext.train_unsupervised(\"pt10.txt\", model='cbow', dim = 300)\n",
    "#model = fasttext.train_unsupervised(\"pt100.txt\", model='cbow', dim = 300)\n",
    "#model = fasttext.train_unsupervised(\"pt1000.txt\", model='cbow', dim = 300)\n",
    "model = fasttext.train_unsupervised(\"pt10000.txt\", model='cbow', dim = 300)"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:20:14.067863Z",
     "start_time": "2024-07-11T17:19:40.384839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the model\n",
    "model.save_model(\"300_cbow_model10000.bin\")"
   ],
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:21:17.225244Z",
     "start_time": "2024-07-11T17:21:11.209222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the model\n",
    "model1 = fasttext.load_model(\"300_cbow_model10000.bin\")"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:21:21.055800Z",
     "start_time": "2024-07-11T17:21:21.030314Z"
    }
   },
   "source": [
    "# Get the word vector for a word\n",
    "word1 = 'king'\n",
    "word2 = 'man'\n",
    "word3  = 'woman'\n",
    "\n",
    "vectorOne1 = model1.get_word_vector(word1)\n",
    "vectorTwo1 = model1.get_word_vector(word2)\n",
    "vectorThree1 = model1.get_word_vector(word3)\n",
    "\n",
    "# Calculate the cosine similarity between two words\n",
    "similarityOne1 = np.dot(vectorOne1, vectorTwo1) / (np.linalg.norm(vectorOne1) * np.linalg.norm(vectorTwo1))\n",
    "similarityTwo1 = np.dot(vectorOne1, vectorThree1) / (np.linalg.norm(vectorOne1) * np.linalg.norm(vectorThree1))\n",
    "\n",
    "# Print the cosine similarity\n",
    "print(f'The cosine similarity between \"{word1}\" and \"{word2}\" using model1 is {similarityOne1:.2f}')\n",
    "print(f'The cosine similarity between \"{word1}\" and \"{word3}\" using model1 is {similarityTwo1:.2f}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between \"king\" and \"man\" using model1 is 0.26\n",
      "The cosine similarity between \"king\" and \"woman\" using model1 is 0.21\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:21:22.076102Z",
     "start_time": "2024-07-11T17:21:21.837522Z"
    }
   },
   "source": [
    "# Load the STS Benchmark dataset from url and extract it\n",
    "sts_dataset = tf.keras.utils.get_file(\n",
    "    fname=\"Stsbenchmark.tar.gz\",\n",
    "    origin=\"http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\",\n",
    "    extract=True)\n",
    "\n",
    "# Load the test set of the STS Benchmark dataset into a pandas DataFrame\n",
    "sts_test = pandas.read_table(\n",
    "    os.path.join(\n",
    "        os.path.dirname(sts_dataset), \"stsbenchmark\", \"sts-test.csv\"),\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    skip_blank_lines=True,\n",
    "    usecols=[4, 5, 6],\n",
    "    names=[\"sim\", \"sent_1\", \"sent_2\"])\n",
    "\n",
    "# Cleanup some NaN values in sts_test\n",
    "sts_test = sts_test[[isinstance(s, str) for s in sts_test['sent_2']]]"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T17:21:28.041868Z",
     "start_time": "2024-07-11T17:21:27.504206Z"
    }
   },
   "source": [
    "# Preprocess a sentence by converting it to lowercase and splitting into words\n",
    "def preprocess_sentence(sentence):\n",
    "  return sentence.lower().split()\n",
    "\n",
    "# Calculate the sentence embedding using average word embeddings\n",
    "def get_sentence_embedding(model, sentence):\n",
    "  return model.get_sentence_vector(sentence)\n",
    "\n",
    "# Evaluate the FastText model on the STS Benchmark data\n",
    "def run_sts_benchmark(model, sts_data):\n",
    "  scores = []\n",
    "  for sent1, sent2, label in zip(sts_data[\"sent_1\"], sts_data[\"sent_2\"], sts_data[\"sim\"]):\n",
    "    # Preprocess sentences\n",
    "    preprocessed_sent1 = preprocess_sentence(sent1)\n",
    "    preprocessed_sent2 = preprocess_sentence(sent2)\n",
    "\n",
    "    # Get sentence embeddings one at a time\n",
    "    sentence1_embedding = get_sentence_embedding(model, \" \".join(preprocessed_sent1))\n",
    "    sentence2_embedding = get_sentence_embedding(model, \" \".join(preprocessed_sent2))\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = 1 - cosine(sentence1_embedding, sentence2_embedding)  # Higher value means more similar\n",
    "      \n",
    "    scores.append(cosine_similarity)\n",
    "  return scores\n",
    "\n",
    "\n",
    "\n",
    "# Load STS Benchmark data\n",
    "sts_data = sts_test\n",
    "\n",
    "# Run STS Benchmark evaluation\n",
    "scores = run_sts_benchmark(model1, sts_data)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "pearson_correlation, pValue = pearsonr(scores, sts_data[\"sim\"])\n",
    "\n",
    "# Print the results\n",
    "print('Pearson correlation coefficient = {0}\\np-value = {1}'.format(pearson_correlation, pValue))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation coefficient = 0.48445245355415056\n",
      "p-value = 4.640136686662976e-82\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
